{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy with all features: \t0.9141122913505311\n",
      "Validation accuracy with all features: \t0.9101723719349356\n",
      "\n",
      "gen\tnevals\tavg     \tstd      \tmin     \tmax     \n",
      "0  \t10    \t0.901184\t0.0062211\t0.887405\t0.909256\n",
      "1  \t6     \t0.904446\t0.00728125\t0.888771\t0.913505\n",
      "2  \t8     \t0.909029\t0.00469246\t0.9     \t0.913505\n",
      "3  \t6     \t0.911775\t0.00335573\t0.901821\t0.913505\n",
      "4  \t4     \t0.912716\t0.000899786\t0.910319\t0.913505\n",
      "5  \t4     \t0.912473\t0.00234671 \t0.905463\t0.913505\n",
      "6  \t6     \t0.913429\t0.000182725\t0.912898\t0.913505\n",
      "7  \t5     \t0.913475\t9.1047e-05 \t0.913202\t0.913505\n",
      "8  \t8     \t0.913384\t0.000364188\t0.912291\t0.913505\n",
      "9  \t3     \t0.91349 \t4.55235e-05\t0.913354\t0.913505\n",
      "10 \t9     \t0.913308\t0.000346365\t0.912443\t0.913505\n",
      "\n",
      "---Optimal Feature Subset(s)---\n",
      "\n",
      "Percentile: \t\t\t0.8181818181818182\n",
      "Validation Accuracy: \t\t0.9099295945617868\n",
      "Individual: \t[1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0]\n",
      "Number Features In Subset: \t9\n",
      "Feature Subset: ['age', 'job', 'education', 'default', 'campaign', 'pdays', 'previous', 'cons.price.idx', 'cons.conf.idx']\n",
      "Percentile: \t\t\t0.9090909090909091\n",
      "Validation Accuracy: \t\t0.9099295945617868\n",
      "Individual: \t[0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1]\n",
      "Number Features In Subset: \t11\n",
      "Feature Subset: ['job', 'default', 'housing', 'loan', 'contact', 'campaign', 'poutcome', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'nr.employed']\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from deap import creator, base, tools, algorithms\n",
    "from scoop import futures\n",
    "import random\n",
    "import numpy\n",
    "from scipy import interpolate\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dfData = pd.read_csv('data.csv', sep=';')\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(dfData['y'])\n",
    "allClasses = le.transform(dfData['y'])\n",
    "allFeatures = dfData.drop(['y'], axis=1)\n",
    "\n",
    "X_trainAndTest, X_validation, y_trainAndTest, y_validation = train_test_split(allFeatures, allClasses, test_size=0.20, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_trainAndTest, y_trainAndTest, test_size=0.20, random_state=42)\n",
    "\n",
    "def getFitness(individual, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    cols = [index for index in range(len(individual)) if individual[index] == 0]\n",
    "    X_trainParsed = X_train.drop(X_train.columns[cols], axis=1)\n",
    "    X_trainOhFeatures = pd.get_dummies(X_trainParsed)\n",
    "    X_testParsed = X_test.drop(X_test.columns[cols], axis=1)\n",
    "    X_testOhFeatures = pd.get_dummies(X_testParsed)\n",
    "\n",
    "    sharedFeatures = set(X_trainOhFeatures.columns) & set(X_testOhFeatures.columns)\n",
    "    removeFromTrain = set(X_trainOhFeatures.columns) - sharedFeatures\n",
    "    removeFromTest = set(X_testOhFeatures.columns) - sharedFeatures\n",
    "    X_trainOhFeatures = X_trainOhFeatures.drop(list(removeFromTrain), axis=1)\n",
    "    X_testOhFeatures = X_testOhFeatures.drop(list(removeFromTest), axis=1)\n",
    "\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_trainOhFeatures, y_train)\n",
    "    predictions = clf.predict(X_testOhFeatures)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "    return (accuracy,)\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, len(dfData.columns) - 1)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", getFitness, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "def getHof():\n",
    "\n",
    "    numPop = 10\n",
    "    numGen = 10\n",
    "    pop = toolbox.population(n=numPop)\n",
    "    hof = tools.HallOfFame(numPop * numGen)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", numpy.mean)\n",
    "    stats.register(\"std\", numpy.std)\n",
    "    stats.register(\"min\", numpy.min)\n",
    "    stats.register(\"max\", numpy.max)\n",
    "\n",
    "    pop, log = algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=numGen, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    return hof\n",
    "\n",
    "def getMetrics(hof):\n",
    "\n",
    "    percentileList = [i / (len(hof) - 1) for i in range(len(hof))]\n",
    "\n",
    "    testAccuracyList = []\n",
    "    validationAccuracyList = []\n",
    "    individualList = []\n",
    "    \n",
    "    for individual in hof:\n",
    "        testAccuracy = individual.fitness.values\n",
    "        validationAccuracy = getFitness(individual, X_trainAndTest, X_validation, y_trainAndTest, y_validation)\n",
    "        testAccuracyList.append(testAccuracy[0])\n",
    "        validationAccuracyList.append(validationAccuracy[0])\n",
    "        individualList.append(individual)\n",
    "    testAccuracyList.reverse()\n",
    "    validationAccuracyList.reverse()\n",
    "    return testAccuracyList, validationAccuracyList, individualList, percentileList\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    individual = [1 for i in range(len(allFeatures.columns))]\n",
    "    testAccuracy = getFitness(individual, X_train, X_test, y_train, y_test)\n",
    "    validationAccuracy = getFitness(individual, X_trainAndTest, X_validation, y_trainAndTest, y_validation)\n",
    "    print('\\nTest accuracy with all features: \\t' + str(testAccuracy[0]))\n",
    "    print('Validation accuracy with all features: \\t' + str(validationAccuracy[0]) + '\\n')\n",
    "\n",
    "    hof = getHof()\n",
    "    testAccuracyList, validationAccuracyList, individualList, percentileList = getMetrics(hof)\n",
    "\n",
    "    maxValAccSubsetIndicies = [index for index in range(len(validationAccuracyList)) if validationAccuracyList[index] == max(validationAccuracyList)]\n",
    "    maxValIndividuals = [individualList[index] for index in maxValAccSubsetIndicies]\n",
    "    maxValSubsets = [[list(allFeatures)[index] for index in range(len(individual)) if individual[index] == 1] for individual in maxValIndividuals]\n",
    "\n",
    "    print('\\n---Optimal Feature Subset(s)---\\n')\n",
    "    for index in range(len(maxValAccSubsetIndicies)):\n",
    "        print('Percentile: \\t\\t\\t' + str(percentileList[maxValAccSubsetIndicies[index]]))\n",
    "        print('Validation Accuracy: \\t\\t' + str(validationAccuracyList[maxValAccSubsetIndicies[index]]))\n",
    "        print('Individual: \\t' + str(maxValIndividuals[index]))\n",
    "        print('Number Features In Subset: \\t' + str(len(maxValSubsets[index])))\n",
    "        print('Feature Subset: ' + str(maxValSubsets[index]))\n",
    "\n",
    "    tck = interpolate.splrep(percentileList, validationAccuracyList, s=5.0)\n",
    "    ynew = interpolate.splev(percentileList, tck)\n",
    "\n",
    "    e = plt.figure(1)\n",
    "    plt.plot(percentileList, validationAccuracyList, marker='o', color='r')\n",
    "    plt.plot(percentileList, ynew, color='b')\n",
    "    plt.title('Validation Set Classification Accuracy vs. \\n Continuum with Cubic-Spline Interpolation')\n",
    "    plt.xlabel('Population Ordered By Increasing Test Set Accuracy')\n",
    "    plt.ylabel('Validation Set Accuracy')\n",
    "    e.show()\n",
    "\n",
    "    f = plt.figure(2)\n",
    "    plt.scatter(percentileList, validationAccuracyList)\n",
    "    plt.title('Validation Set Classification Accuracy vs. Continuum')\n",
    "    plt.xlabel('Population Ordered By Increasing Test Set Accuracy')\n",
    "    plt.ylabel('Validation Set Accuracy')\n",
    "    f.show()\n",
    "\n",
    "    g = plt.figure(3)\n",
    "    plt.scatter(percentileList, testAccuracyList)\n",
    "    plt.title('Test Set Classification Accuracy vs. Continuum')\n",
    "    plt.xlabel('Population Ordered By Increasing Test Set Accuracy')\n",
    "    plt.ylabel('Test Set Accuracy')\n",
    "    g.show()\n",
    "\n",
    "    input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
