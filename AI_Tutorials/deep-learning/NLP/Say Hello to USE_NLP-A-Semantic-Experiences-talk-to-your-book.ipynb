{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Mighty USE of NLP -- Universal Sentence Encoder\n",
    "\n",
    "This notebook illustrates how to access the Universal Sentence Encoder and use it for sentence similarity and sentence classification tasks.\n",
    "\n",
    "The Universal Sentence Encoder makes getting sentence level embeddings as easy as it has historically been to lookup the embeddings for individual words. The sentence embeddings can then be trivially used to compute sentence level meaning similarity as well as to enable better performance on downstream classification tasks using less supervised training data.\n",
    "\n",
    "[Link to arxiv paper is here](https://arxiv.org/abs/1803.11175)\n",
    "\n",
    "## Talk to Books\n",
    "\n",
    "<img src=\"images/Talk2Books.png\">\n",
    "\n",
    "\n",
    "[Natural language understanding](https://en.wikipedia.org/wiki/Natural_language_understanding) has evolved substantially in the past few years, in part due to the development of [word vectors](https://www.tensorflow.org/tutorials/word2vec) that enable algorithms to learn about the relationships between words, based on examples of actual language usage. These vector models map semantically similar phrases to nearby points based on equivalence, similarity or relatedness of ideas and language. Last year, we used hierarchical vector models of language to make improvements to [Smart Reply for Gmail](https://research.googleblog.com/2017/05/efficient-smart-reply-now-for-gmail.html). More recently, we’ve been exploring other applications of these methods. \n",
    "\n",
    "Today, we are proud to share Semantic Experiences, a website showing two examples of how these new capabilities can drive applications that weren’t possible before. Talk to Books is an entirely new way to explore books by starting at the sentence level, rather than the author or topic level. Semantris is a word association game powered by machine learning, where you type out words associated with a given prompt. We have also published “Universal Sentence Encoder”, or as I call it **USE** which describes the models used for these examples in more detail. Lastly, we’ve provided a [pretrained semantic TensorFlow module](https://tfhub.dev/google/universal-sentence-encoder/1) for the community to experiment with their own sentence and phrase encoding. \n",
    "\n",
    "#### Modeling approach\n",
    "Our approach extends the idea of representing language in a vector space by creating vectors for larger chunks of language such as full sentences and small paragraphs. Since language is composed of hierarchies of concepts, we create the vectors using a hierarchy of modules, each of which considers features that correspond to sequences at different temporal scales. Relatedness, synonymy, antonymy, meronymy, holonymy, and many other types of relationships may all be represented in vector space language models if we train them in the right way and then pose the right “questions”. We describe this method in our paper, [“Efficient Natural Language Response for Smart Reply.”](https://arxiv.org/abs/1705.00652) \n",
    "\n",
    "#### Talk to Books\n",
    "\n",
    "With [Talk to Books](https://books.google.com/talktobooks), we provide an entirely new way to explore books. You make a statement or ask a question, and the tool finds sentences in books that respond, with no dependence on keyword matching. In a sense you are talking to the books, getting responses which can help you determine if you’re interested in reading them or not. \n",
    "\n",
    "A bit more on the Pre-trained model\n",
    "--------------------\n",
    "\n",
    "The Universal Sentence Encoder encodes text into high dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks.\n",
    "\n",
    "The model is trained and optimized for greater-than-word length text, such as sentences, phrases or short paragraphs. It is trained on a variety of data sources and a variety of tasks with the aim of dynamically accommodating a wide variety of natural language understanding tasks. The input is variable length English text and the output is a 512 dimensional vector. We apply this model to the STS benchmark for semantic similarity, and the results can be seen in the example notebook made available. To learn more about text embeddings, refer to the TensorFlow Embeddings documentation. Our encoder differs from word level embedding models in that we train on a number of natural language prediction tasks that require modeling the meaning of word sequences rather than just individual words. Details are available in the paper \"Universal Sentence Encoder\" [1].\n",
    "\n",
    "<img src=\"images/example-similarity.png\">\n",
    "\n",
    "**Semantic similarity** is a measure of the degree to which two pieces of text carry the same meaning. This is broadly useful in obtaining good coverage over the numerous ways that a thought can be expressed using language without needing to manually enumerate them.\n",
    "\n",
    "Simple applications include improving the coverage of systems that trigger behaviors on certain keywords, phrases or utterances. This section of the notebook shows how to encode text and compare encoding distances as a proxy for semantic similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 2\n",
    "\n",
    "- Get Universal Sentence Encoder's TF Hub module\n",
    "- Compute representation\n",
    "- Reduce logging output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_0:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_0\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_1:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_1\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_10:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_10\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_11:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_11\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_12:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_12\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_13:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_13\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_14:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_14\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_15:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_15\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_16:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_16\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_2:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_2\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_3:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_3\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_4:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_4\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_5:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_5\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_6:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_6\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_7:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_7\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_8:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_8\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_9:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Embeddings_en/sharded_9\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_0/weights:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Encoder_en/DNN/ResidualHidden_0/weights\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_1/weights:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Encoder_en/DNN/ResidualHidden_1/weights\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_2/weights:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Encoder_en/DNN/ResidualHidden_2/weights\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_3/projection:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Encoder_en/DNN/ResidualHidden_3/projection\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_3/weights:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with Encoder_en/DNN/ResidualHidden_3/weights\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_0/bias:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_0/bias\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_0/weights:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_0/weights\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_1/bias:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_1/bias\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_1/weights:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_1/weights\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_2/bias:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_2/bias\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_2/weights:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_2/weights\n",
      "INFO:tensorflow:Initialize variable module/SNLI/Classifier/LinearLayer/bias:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with SNLI/Classifier/LinearLayer/bias\n",
      "INFO:tensorflow:Initialize variable module/SNLI/Classifier/LinearLayer/weights:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with SNLI/Classifier/LinearLayer/weights\n",
      "INFO:tensorflow:Initialize variable module/SNLI/Classifier/tanh_layer_0/bias:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with SNLI/Classifier/tanh_layer_0/bias\n",
      "INFO:tensorflow:Initialize variable module/SNLI/Classifier/tanh_layer_0/weights:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with SNLI/Classifier/tanh_layer_0/weights\n",
      "INFO:tensorflow:Initialize variable module/global_step:0 from checkpoint b'/tmp/tfhub_modules/c6f5954ffa065cdb2f2e604e740e8838bf21a2d3/variables/variables' with global_step\n",
      "Message: Elephant\n",
      "Embedding size: 512\n",
      "Embedding: [-0.016987277194857597, -0.008949832059442997, -0.007062744814902544, ...]\n",
      "\n",
      "Message: I am a sentence for which I would like to get its embedding.\n",
      "Embedding size: 512\n",
      "Embedding: [0.035313352942466736, -0.025384247303009033, -0.007880019024014473, ...]\n",
      "\n",
      "Message: Universal Sentence Encoder embeddings also support short paragraphs. There is no hard limit on how long the paragraph is. Roughly, the longer the more 'diluted' the embedding will be.\n",
      "Embedding size: 512\n",
      "Embedding: [0.01879095286130905, 0.04536514729261398, -0.020010896027088165, ...]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/1\")\n",
    "\n",
    "# Compute a representation for each message, showing various lengths supported.\n",
    "word = \"Elephant\"\n",
    "sentence = \"I am a sentence for which I would like to get its embedding.\"\n",
    "paragraph = (\n",
    "    \"Universal Sentence Encoder embeddings also support short paragraphs. \"\n",
    "    \"There is no hard limit on how long the paragraph is. Roughly, the longer \"\n",
    "    \"the more 'diluted' the embedding will be.\")\n",
    "messages = [word, sentence, paragraph]\n",
    "\n",
    "# Reduce logging output.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "with tf.Session() as session:\n",
    "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "  message_embeddings = session.run(embed(messages))\n",
    "\n",
    "  for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
    "    print(\"Message: {}\".format(messages[i]))\n",
    "    print(\"Embedding size: {}\".format(len(message_embedding)))\n",
    "    message_embedding_snippet = \", \".join(\n",
    "        (str(x) for x in message_embedding[:3]))\n",
    "    print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Semantic Textual Similarity Task Example\n",
    "\n",
    "The embeddings produced by the USE are approximately normalized. The semantic similarity of two sentences can be triviially computed as the inner product of the encodings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_similarity(labels, features, rotation):\n",
    "    corr = np.inner(features, features)\n",
    "    sns.set(font_scale=1.2)\n",
    "    g = sns.heatmap(corr, xticklabels=labels, yticklabels=labels, vmin=0, vmax=1, cmap=\"YlOrRd\")\n",
    "    g.set_xticklabels(labels, rotation=rotation)\n",
    "    g.set_title(\"Semantic Textual Similarity\")\n",
    "\n",
    "\n",
    "def run_and_plot(session_, input_tensor_, messages_, encoding_tensor):\n",
    "    message_embeddings_ = session_.run(\n",
    "        encoding_tensor, feed_dict={input_tensor_: messages})\n",
    "    plot_similarity(messages_, message_embeddings_, 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Visualization\n",
    "\n",
    "Here we show the similarity in a heat map. Finla graph is a 9x9 matrix where each entry `[i, j]` is colored based on the inner product of gthe encodings for sentence `i` and `j`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    # Smartphones\n",
    "    \"I like my phone\",\n",
    "    \"My phone is not good.\",\n",
    "    \"Your cellphone looks great.\",\n",
    "\n",
    "    # Weather\n",
    "    \"Will it snow tomorrow?\",\n",
    "    \"Recently a lot of hurricanes have hit the US\",\n",
    "    \"Global warming is real\",\n",
    "\n",
    "    # Food and health\n",
    "    \"An apple a day, keeps the doctors away\",\n",
    "    \"Eating strawberries is healthy\",\n",
    "    \"Is paleo better than keto?\",\n",
    "\n",
    "    # Asking about age\n",
    "    \"How old are you?\",\n",
    "    \"what is your age?\",\n",
    "]\n",
    "\n",
    "similarity_input_placeholder = tf.placeholder(tf.string, shape=(None))\n",
    "similarity_message_encodings = embed(similarity_input_placeholder)\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    run_and_plot(session, similarity_input_placeholder, messages,\n",
    "                 similarity_message_encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing the evaluation : STS (Semantic Textual Similarity) Benchmark \n",
    "\n",
    "The [STS Benchmark](http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark) provides an intristic evaluation of the degree to which similarity scores computed using sentence embeddings align with human judgements. The benchmark requires systems to return similarity scores for a diverse selection of sentence pairs. [Pearson correlation](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) is then used to evaluate the quality of the machine similarity scores against human judgements.\n",
    "\n",
    "#### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import scipy\n",
    "import math\n",
    "\n",
    "\n",
    "def load_sts_dataset(filename):\n",
    "  # Loads a subset of the STS dataset into a DataFrame. In particular both\n",
    "  # sentences and their human rated similarity score.\n",
    "    sent_pairs = []\n",
    "    with tf.gfile.GFile(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            ts = line.strip().split(\"\\t\")\n",
    "            # (sent_1, sent_2, similarity_score)\n",
    "            sent_pairs.append((ts[5], ts[6], float(ts[4])))\n",
    "            return pandas.DataFrame(sent_pairs, columns=[\"sent_1\", \"sent_2\", \"sim\"])\n",
    "\n",
    "\n",
    "def download_and_load_sts_data():\n",
    "    sts_dataset = tf.keras.utils.get_file(\n",
    "        fname=\"Stsbenchmark.tar.gz\",\n",
    "        origin=\"http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\",\n",
    "        extract=True)\n",
    "    \n",
    "    sts_dev = load_sts_dataset(\n",
    "      os.path.join(os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-dev.csv\"))\n",
    "    sts_test = load_sts_dataset(\n",
    "      os.path.join(\n",
    "          os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-test.csv\"))\n",
    "\n",
    "    return sts_dev, sts_test\n",
    "\n",
    "\n",
    "sts_dev, sts_test = download_and_load_sts_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Evaluation Graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_a = sts_dev['sent_1'].tolist()\n",
    "text_b = sts_dev['sent_2'].tolist()\n",
    "dev_scores = sts_dev['sim'].tolist()\n",
    "sts_input1 = tf.placeholder(tf.string, shape=(None))\n",
    "sts_input2 = tf.placeholder(tf.string, shape=(None))\n",
    "\n",
    "# For evaluation we use exactly normalized rather than\n",
    "# approximately normalized.\n",
    "sts_encode1 = tf.nn.l2_normalize(embed(sts_input1))\n",
    "sts_encode2 = tf.nn.l2_normalize(embed(sts_input2))\n",
    "sim_scores = tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"l2_normalize:0\", shape=(?, 512), dtype=float32)\n",
      "Tensor(\"Sum:0\", shape=(?,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(sts_encode1)\n",
    "print(sim_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Sentence Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_sts_benchmark(session):\n",
    "    \"\"\"Returns the similarity scores\"\"\"\n",
    "    emba, embb, scores = session.run(\n",
    "        [sts_encode1, sts_encode2, sim_scores],\n",
    "        feed_dict={sts_input1: text_a, sts_input2: text_b})\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient = nan\n",
      "p-value = nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deeplearn/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:3021: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  r = r_num / r_den\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    scores = run_sts_benchmark(session)\n",
    "\n",
    "pearson_correlation = scipy.stats.pearsonr(scores, dev_scores)\n",
    "print('Pearson correlation coefficient = {0}\\np-value = {1}'.format(\n",
    "    pearson_correlation[0], pearson_correlation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "<img src=\"images/example-classification.png\">\n",
    "\n",
    "Below you see how to train a simple binary text classifier on top of any TF-Hub module that can embed sentences. The Universal Sentence Encoder was partly trained with custom text classification tasks in mind. It can be trained to perform a wide variety of classification tasks often with a very small amount of labeled examples.\n",
    "\n",
    "## How to build a simple text classifier with TF-Hub\n",
    "\n",
    "TF-Hub is a platform to share machine learning expertise packaged in reusable resources, notably pre-trained modules. This tutorial is organized into two main parts.\n",
    "\n",
    "#### Introduction: Training a text classifier with TF-Hub\n",
    "We will use a TF-Hub text embedding module to train a simple sentiment classifier with a reasonable baseline accuracy. We will then analyze the predictions to make sure our model is reasonable and propose improvements to increase the accuracy.\n",
    "\n",
    "#### Advanced: Transfer learning analysis\n",
    "In this section, we will use various TF-Hub modules to compare their effect on the accuracy of the estimator and demonstrate advantages and pitfalls of transfer learning.\n",
    "\n",
    "### Getting the Data\n",
    "\n",
    "We will try to solve the **[Large Movie Review Dataset v1.0](http://ai.stanford.edu/~amaas/data/sentiment/)** task from Mass et al. The dataset consists of IMDB movie reviews labeled by positivity from 1 to 10. The task is to label the reviews as **negative** or **positive**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jafar Panahi's comedy-drama \"Offside\" portrays...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This movie is AWESOME. I watched it the other ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I caught this at a test screening. All I can s...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>At first I wasn't sure if I wanted to watch th...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Domestic Import was a great movie. I laughed t...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence sentiment  polarity\n",
       "0  Jafar Panahi's comedy-drama \"Offside\" portrays...         7         1\n",
       "1  This movie is AWESOME. I watched it the other ...         1         0\n",
       "2  I caught this at a test screening. All I can s...         3         0\n",
       "3  At first I wasn't sure if I wanted to watch th...         9         1\n",
       "4  Domestic Import was a great movie. I laughed t...        10         1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all files from a directory in a DataFrame.\n",
    "def load_directory_data(directory):\n",
    "    data = {}\n",
    "    data[\"sentence\"] = []\n",
    "    data[\"sentiment\"] = []\n",
    "    for file_path in os.listdir(directory):\n",
    "        with tf.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
    "            data[\"sentence\"].append(f.read())\n",
    "            data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
    "    return pd.DataFrame.from_dict(data)\n",
    "\n",
    "# Merge positive and negative examples, add a polarity column and shuffle.\n",
    "def load_dataset(directory):\n",
    "    pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
    "    neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
    "    pos_df[\"polarity\"] = 1\n",
    "    neg_df[\"polarity\"] = 0\n",
    "    return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Download and process the dataset files.\n",
    "def download_and_load_datasets(force_download=False):\n",
    "    dataset = tf.keras.utils.get_file(\n",
    "        fname=\"aclImdb.tar.gz\", \n",
    "        origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
    "        extract=True)\n",
    "    \n",
    "    train_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
    "                                       \"aclImdb\", \"train\"))\n",
    "    test_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
    "                                      \"aclImdb\", \"test\"))\n",
    "    return train_df, test_df\n",
    "\n",
    "# Reduce logging output.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "train_df, test_df = download_and_load_datasets()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model\n",
    "\n",
    "**Input functions**\n",
    "\n",
    "[Estimator framework](https://www.tensorflow.org/get_started/premade_estimators#overview_of_programming_with_estimators) provides [input functions](https://www.tensorflow.org/api_docs/python/tf/estimator/inputs/pandas_input_fn) that wrap Pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training input on the whole training set with no limit on training epochs.\n",
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    train_df, train_df[\"polarity\"], num_epochs=None, shuffle=True)\n",
    "\n",
    "# Prediction on the whole training set.\n",
    "predict_train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    train_df, train_df[\"polarity\"], shuffle=False)\n",
    "# Prediction on the test set.\n",
    "predict_test_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    test_df, test_df[\"polarity\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature columns\n",
    "\n",
    "**TF-Hub** provides a [feature column](https://github.com/tensorflow/hub/blob/r0.1/docs/api_docs/python/hub/text_embedding_column.md) that applies a module on the given text feature and passes further the outputs of the module. In this tutorial we will be using the [nnlm-en-dim128 module](https://tfhub.dev/google/nnlm-en-dim128/1). \n",
    "\n",
    "For the purpose of this tutorial, the most important facts are:\n",
    "\n",
    "- The module takes a batch of sentences in a 1-D tensor of strings as input.\n",
    "- The module is responsible for preprocessing of sentences (e.g. removal of punctuation and splitting on spaces).\n",
    "- The module works with any input (e.g. nnlm-en-dim128 hashes words not present in vocabulary into ~20.000 buckets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedded_text_feature_column = hub.text_embedding_column(\n",
    "    key=\"sentence\", \n",
    "    module_spec=\"https://tfhub.dev/google/nnlm-en-dim128/1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimator\n",
    "\n",
    "For classification we can use a TensorFlow [DNN Classifier](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tf.estimator.DNNClassifier(\n",
    "    hidden_units = [500, 100],\n",
    "    feature_columns = [embedded_text_feature_column],\n",
    "    n_classes = 2,\n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate=0.003))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "\n",
    "Train the estimator for a resonable amount of steps. I went on to do it for 10000 steps on my GPU! ☺️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7f09dbea7630>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training for 1,000 steps means 128,000 training examples with the default\n",
    "# batch size. This is roughly equivalent to 50 epochs since the training dataset\n",
    "# contains 25,000 examples.\n",
    "estimator.train(input_fn=train_input_fn, steps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction \n",
    "\n",
    "Lets now run the predictions for both training and test sets.\n",
    "(Try increasing number of steps and/or num of hidden layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.8450000286102295\n",
      "Test set accuracy: 0.8015599846839905\n"
     ]
    }
   ],
   "source": [
    "train_eval_accuracy = estimator.evaluate(input_fn=predict_train_input_fn)\n",
    "test_eval_accuracy  = estimator.evaluate(input_fn=predict_test_input_fn)\n",
    "\n",
    "print(\"Training set accuracy: {accuracy}\".format(**train_eval_accuracy))\n",
    "print(\"Test set accuracy: {accuracy}\".format(**test_eval_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7f09dbea7630>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training for 100000 steps, around 500 epochs approximately\n",
    "estimator.train(input_fn=train_input_fn, steps=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See if our prediction improves? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.9903200268745422\n",
      "Test set accuracy: 0.763480007648468\n"
     ]
    }
   ],
   "source": [
    "train_eval_accuracy = estimator.evaluate(input_fn=predict_train_input_fn)\n",
    "test_eval_accuracy  = estimator.evaluate(input_fn=predict_test_input_fn)\n",
    "\n",
    "print(\"Training set accuracy: {accuracy}\".format(**train_eval_accuracy))\n",
    "print(\"Test set accuracy: {accuracy}\".format(**test_eval_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Lets now check visually the confusion matrix to understand the distribution of these (corrent and incorrect) classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f0742f5be80>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEPCAYAAACp/QjLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUHAQEZEM/w+UwEX1p+2jgAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0743b3ff98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_predictions(estimator, input_fn):\n",
    "    return [x[\"class_ids\"][0] for x in estimator.predict(input_fn=input_fn)]\n",
    "\n",
    "LABELS = [\n",
    "    \"negative\", \"positive\"\n",
    "]\n",
    "\n",
    "# Create a confusion matrix on training data.\n",
    "with tf.Graph().as_default():\n",
    "    conf_matrix = tf.confusion_matrix(train_df[\"polarity\"], \n",
    "                                      get_predictions(estimator, predict_train_input_fn))\n",
    "    with tf.Session() as session:\n",
    "        conf_matrix_out = session.run(conf_matrix)\n",
    "\n",
    "# Normalize the confusion matrix so that each row sums to 1.\n",
    "conf_matix_out = conf_matrix_out.astype(float) / conf_matrix_out.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "sns.heatmap(conf_matrix_out, annot=True, xticklabels=LABELS, yticklabels=LABELS)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced NLP Stuff: Transfer Learning Analysis\n",
    "***\n",
    "\n",
    "Transfer learning makes it possible to save training resources and to achieve good model generalization even when training on a small dataset. In this part, we will demonstrate this by training with two different TF-Hub modules:\n",
    "1. **[nnlm-en-dim128]()** - pretrained text embedding module,\n",
    "2. **[random-nnlm-en-dim128]()** - text embedding module that has same vocabulary and network as nnlm-en-dim128, but the weights were just randomly initialized and never trained on real data.\n",
    "\n",
    "And by training in two modes:\n",
    "1. training **<font color=blue>only the classifier</font>** (i.e. freezing the module), and\n",
    "2. training the **<font color=blue>classifier together with the module</font>.**\n",
    "\n",
    "\n",
    "### A bit about Transfer Learning (courtesy Stanford Course)\n",
    "***\n",
    "\n",
    "#### Transfer Learning\n",
    "\n",
    "In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest. The three major Transfer Learning scenarios look as follows:\n",
    "\n",
    "1. **ConvNet as fixed feature extractor.** Take a ConvNet pretrained on ImageNet, remove the last fully-connected layer (this layer’s outputs are the 1000 class scores for a different task like ImageNet), then treat the rest of the ConvNet as a fixed feature extractor for the new dataset. In an AlexNet, this would compute a 4096-D vector for every image that contains the activations of the hidden layer immediately before the classifier. We call these features CNN codes. It is important for performance that these codes are ReLUd (i.e. thresholded at zero) if they were also thresholded during the training of the ConvNet on ImageNet (as is usually the case). Once you extract the 4096-D codes for all images, train a linear classifier (e.g. Linear SVM or Softmax classifier) for the new dataset.\n",
    "2. **Fine-tuning the ConvNet.** The second strategy is to not only replace and retrain the classifier on top of the ConvNet on the new dataset, but to also fine-tune the weights of the pretrained network by continuing the backpropagation. It is possible to fine-tune all the layers of the ConvNet, or it’s possible to keep some of the earlier layers fixed (due to overfitting concerns) and only fine-tune some higher-level portion of the network. This is motivated by the observation that the earlier features of a ConvNet contain more generic features (e.g. edge detectors or color blob detectors) that should be useful to many tasks, but later layers of the ConvNet becomes progressively more specific to the details of the classes contained in the original dataset. In case of ImageNet for example, which contains many dog breeds, a significant portion of the representational power of the ConvNet may be devoted to features that are specific to differentiating between dog breeds.\n",
    "3. **Pretrained models.** Since modern ConvNets take 2-3 weeks to train across multiple GPUs on ImageNet, it is common to see people release their final ConvNet checkpoints for the benefit of others who can use the networks for fine-tuning. For example, the Caffe library has a Model Zoo where people share their network weights.\n",
    "\n",
    "##### When and how to fine-tune?\n",
    "\n",
    "How do you decide what type of transfer learning you should perform on a new dataset? This is a function of several factors, but the two most important ones are the size of the new dataset (small or big), and its similarity to the original dataset (e.g. ImageNet-like in terms of the content of images and the classes, or very different, such as microscope images). Keeping in mind that ConvNet features are more generic in early layers and more original-dataset-specific in later layers, here are some common rules of thumb for navigating the 4 major scenarios:\n",
    "\n",
    "1. New dataset is small and similar to original dataset. Since the data is small, it is not a good idea to fine-tune the ConvNet due to overfitting concerns. Since the data is similar to the original data, we expect higher-level features in the ConvNet to be relevant to this dataset as well. Hence, the best idea might be to train a linear classifier on the CNN codes.\n",
    "2. New dataset is large and similar to the original dataset. Since we have more data, we can have more confidence that we won’t overfit if we were to try to fine-tune through the full network.\n",
    "3. New dataset is small but very different from the original dataset. Since the data is small, it is likely best to only train a linear classifier. Since the dataset is very different, it might not be best to train the classifier form the top of the network, which contains more dataset-specific features. Instead, it might work better to train the SVM classifier from activations somewhere earlier in the network.\n",
    "4. New dataset is large and very different from the original dataset. Since the dataset is very large, we may expect that we can afford to train a ConvNet from scratch. However, in practice it is very often still beneficial to initialize with weights from a pretrained model. In this case, we would have enough data and confidence to fine-tune through the entire network.\n",
    "\n",
    "Some Practical advice. There are a few additional things to keep in mind when performing Transfer Learning:\n",
    "\n",
    "1. **Constraints from pretrained models.** Note that if you wish to use a pretrained network, you may be slightly constrained in terms of the architecture you can use for your new dataset. For example, you can’t arbitrarily take out Conv layers from the pretrained network. However, some changes are straight-forward: Due to parameter sharing, you can easily run a pretrained network on images of different spatial size. This is clearly evident in the case of Conv/Pool layers because their forward function is independent of the input volume spatial size (as long as the strides “fit”). In case of FC layers, this still holds true because FC layers can be converted to a Convolutional Layer: For example, in an AlexNet, the final pooling volume before the first FC layer is of size [6x6x512]. Therefore, the FC layer looking at this volume is equivalent to having a Convolutional Layer that has receptive field size 6x6, and is applied with padding of 0.\n",
    "2. **Learning rates.** It’s common to use a smaller learning rate for ConvNet weights that are being fine-tuned, in comparison to the (randomly-initialized) weights for the new linear classifier that computes the class scores of your new dataset. This is because we expect that the ConvNet weights are relatively good, so we don’t wish to distort them too quickly and too much (especially while the new Linear Classifier above them is being trained from random initialization).\n",
    "\n",
    "\n",
    "OK, lets try some more trainings and evaluations and see how we can use various modules to improve the accuracy and hopefully not overfit as dramatically as above (when we tried just blatantly increasing the number of steps):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_with_module(hub_module, train_module=False):\n",
    "    embedded_text_feature_column = hub.text_embedding_column(\n",
    "        key=\"sentence\", module_spec=hub_module, trainable=train_module)\n",
    "    \n",
    "    estimator = tf.estimator.DNNClassifier(\n",
    "        hidden_units=[500, 100],\n",
    "        feature_columns=[embedded_text_feature_column],\n",
    "        n_classes=2,\n",
    "        optimizer=tf.train.AdagradOptimizer(learning_rate=0.003))\n",
    "    \n",
    "    estimator.train(input_fn=train_input_fn, steps=1000)\n",
    "    train_eval_result = estimator.evaluate(input_fn=predict_train_input_fn)\n",
    "    test_eval_result = estimator.evaluate(input_fn=predict_test_input_fn)\n",
    "    \n",
    "    training_set_accuracy = train_eval_result[\"accuracy\"]\n",
    "    test_set_accuracy = test_eval_result[\"accuracy\"]\n",
    "    \n",
    "    return {\n",
    "      \"Training accuracy\": training_set_accuracy,\n",
    "      \"Test accuracy\": test_set_accuracy\n",
    "  }\n",
    "\n",
    "\n",
    "results = {}\n",
    "results[\"nnlm-en-dim128\"] = train_and_evaluate_with_module(\n",
    "    \"https://tfhub.dev/google/nnlm-en-dim128/1\")\n",
    "results[\"nnlm-en-dim128-with-module-training\"] = train_and_evaluate_with_module(\n",
    "    \"https://tfhub.dev/google/nnlm-en-dim128/1\", True)\n",
    "results[\"random-nnlm-en-dim128\"] = train_and_evaluate_with_module(\n",
    "    \"https://tfhub.dev/google/random-nnlm-en-dim128/1\")\n",
    "results[\"random-nnlm-en-dim128-with-module-training\"] = train_and_evaluate_with_module(\n",
    "    \"https://tfhub.dev/google/random-nnlm-en-dim128/1\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nnlm-en-dim128</th>\n",
       "      <td>0.80272</td>\n",
       "      <td>0.79344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nnlm-en-dim128-with-module-training</th>\n",
       "      <td>0.95076</td>\n",
       "      <td>0.87104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random-nnlm-en-dim128</th>\n",
       "      <td>0.71772</td>\n",
       "      <td>0.67156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random-nnlm-en-dim128-with-module-training</th>\n",
       "      <td>0.76564</td>\n",
       "      <td>0.72012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Training accuracy  Test accuracy\n",
       "nnlm-en-dim128                                        0.80272        0.79344\n",
       "nnlm-en-dim128-with-module-training                   0.95076        0.87104\n",
       "random-nnlm-en-dim128                                 0.71772        0.67156\n",
       "random-nnlm-en-dim128-with-module-training            0.76564        0.72012"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the results\n",
    "pd.DataFrame.from_dict(results, orient=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Do we like what we see?\n",
    "\n",
    "We can already see some patterns, such as `nnlm-en-dim128-with-module-training` is doing far better than the `nnlm-en-dim128` and same for random-nnlm as well.\n",
    "How about we also but first establish the baseline accuracy of the test set - the lower bound that can be achieved by outputting only the label of the most represented class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.evaluate(input_fn=predict_test_input_fn)[\"accuracy_baseline\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And so, what we see?\n",
    "\n",
    "Assigning the most represented class will give us accuracy of 50%. There are a couple of things to notice here:\n",
    "1. Maybe surprisingly, a **model can still be learned on top of fixed, random embeddings**\n",
    ". The reason is that even if every word in the dictionary is mapped to a random vector, the estimator can separate the space purely using its fully connected layers.\n",
    "2. Allowing training of the module with **random embeddings** increases both training and test accuracy as oposed to training just the classifier.\n",
    "3. Training of the module with **pre-trained embeddings** also increases both accuracies. Note however the overfitting on the training set. As you saw above when we ran about 500 epochs worth of steps (100,000). Training a pre-trained module can be dangerous even with regularization in the sense that the embedding weights no longer represent the language model trained on diverse data, instead they converge to the ideal representation of the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
